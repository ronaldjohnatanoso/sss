2024-07-06 11:31:29,010 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Current SDK version is 0.17.4
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Configure stats pid to 4752
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Loading settings from C:\Users\Ronald\.config\wandb\settings
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Loading settings from D:\thesis\nanoGPT\wandb\settings
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program_abspath': 'D:\\thesis\\nanoGPT\\train.py', 'program': 'D:\\thesis\\nanoGPT\\train.py'}
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_init.py:_log_setup():529] Logging user logs to D:\thesis\nanoGPT\wandb\run-20240706_113129-2fztv1cx\logs\debug.log
2024-07-06 11:31:29,012 INFO    MainThread:4752 [wandb_init.py:_log_setup():530] Logging internal logs to D:\thesis\nanoGPT\wandb\run-20240706_113129-2fztv1cx\logs\debug-internal.log
2024-07-06 11:31:29,014 INFO    MainThread:4752 [wandb_init.py:init():569] calling init triggers
2024-07-06 11:31:29,014 INFO    MainThread:4752 [wandb_init.py:init():576] wandb.init called with sweep_config: {}
config: {'out_dir': 'out-test', 'eval_interval': 1000, 'log_interval': 10, 'eval_iters': 200, 'eval_only': False, 'always_save_checkpoint': True, 'init_from': 'scratch', 'wandb_log': True, 'wandb_project': 'test-shakespeare-gpt2-smallest', 'wandb_run_name': 'initial-test-shakespeare-gpt2-smallest', 'dataset': 'testshakespeare', 'gradient_accumulation_steps': 24, 'batch_size': 6, 'block_size': 512, 'n_layer': 12, 'n_head': 12, 'n_embd': 768, 'dropout': 0.0, 'bias': False, 'learning_rate': 0.0006, 'max_iters': 600000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 600000, 'min_lr': 6e-05, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': False}
2024-07-06 11:31:29,014 INFO    MainThread:4752 [wandb_init.py:init():619] starting backend
2024-07-06 11:31:29,014 INFO    MainThread:4752 [wandb_init.py:init():623] setting up manager
2024-07-06 11:31:29,016 INFO    MainThread:4752 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn, using: spawn
2024-07-06 11:31:29,019 INFO    MainThread:4752 [wandb_init.py:init():631] backend started and connected
2024-07-06 11:31:29,025 INFO    MainThread:4752 [wandb_init.py:init():720] updated telemetry
2024-07-06 11:31:29,090 INFO    MainThread:4752 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-07-06 11:31:29,940 INFO    MainThread:4752 [wandb_run.py:_on_init():2402] communicating current version
2024-07-06 11:31:30,370 INFO    MainThread:4752 [wandb_run.py:_on_init():2411] got version response 
2024-07-06 11:31:30,370 INFO    MainThread:4752 [wandb_init.py:init():804] starting run threads in backend
2024-07-06 11:31:30,762 INFO    MainThread:4752 [wandb_run.py:_console_start():2380] atexit reg
2024-07-06 11:31:30,762 INFO    MainThread:4752 [wandb_run.py:_redirect():2235] redirect: wrap_raw
2024-07-06 11:31:30,762 INFO    MainThread:4752 [wandb_run.py:_redirect():2300] Wrapping output streams.
2024-07-06 11:31:30,762 INFO    MainThread:4752 [wandb_run.py:_redirect():2325] Redirects installed.
2024-07-06 11:31:30,764 INFO    MainThread:4752 [wandb_init.py:init():847] run started, returning control to user process
2024-07-06 22:32:03,562 WARNING MsgRouterThr:4752 [router.py:message_loop():77] message_loop has been closed
