2024-07-06 11:22:10,114 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Current SDK version is 0.17.4
2024-07-06 11:22:10,114 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Configure stats pid to 12772
2024-07-06 11:22:10,114 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Loading settings from C:\Users\Ronald\.config\wandb\settings
2024-07-06 11:22:10,114 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Loading settings from D:\thesis\nanoGPT\wandb\settings
2024-07-06 11:22:10,114 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-07-06 11:22:10,114 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-07-06 11:22:10,115 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program_abspath': 'D:\\thesis\\nanoGPT\\train.py', 'program': 'D:\\thesis\\nanoGPT\\train.py'}
2024-07-06 11:22:10,115 INFO    MainThread:12772 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-07-06 11:22:10,115 INFO    MainThread:12772 [wandb_init.py:_log_setup():529] Logging user logs to D:\thesis\nanoGPT\wandb\run-20240706_112210-lu4t7qr7\logs\debug.log
2024-07-06 11:22:10,115 INFO    MainThread:12772 [wandb_init.py:_log_setup():530] Logging internal logs to D:\thesis\nanoGPT\wandb\run-20240706_112210-lu4t7qr7\logs\debug-internal.log
2024-07-06 11:22:10,116 INFO    MainThread:12772 [wandb_init.py:init():569] calling init triggers
2024-07-06 11:22:10,116 INFO    MainThread:12772 [wandb_init.py:init():576] wandb.init called with sweep_config: {}
config: {'out_dir': 'out-test', 'eval_interval': 1000, 'log_interval': 10, 'eval_iters': 200, 'eval_only': False, 'always_save_checkpoint': True, 'init_from': 'scratch', 'wandb_log': True, 'wandb_project': 'test-shakespeare-gpt2-smallest', 'wandb_run_name': 'initial-test-shakespeare-gpt2-smallest', 'dataset': 'testshakespeare', 'gradient_accumulation_steps': 24, 'batch_size': 6, 'block_size': 512, 'n_layer': 12, 'n_head': 12, 'n_embd': 768, 'dropout': 0.0, 'bias': False, 'learning_rate': 0.0006, 'max_iters': 600000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 2000, 'lr_decay_iters': 600000, 'min_lr': 6e-05, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': False}
2024-07-06 11:22:10,116 INFO    MainThread:12772 [wandb_init.py:init():619] starting backend
2024-07-06 11:22:10,116 INFO    MainThread:12772 [wandb_init.py:init():623] setting up manager
2024-07-06 11:22:10,118 INFO    MainThread:12772 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn, using: spawn
2024-07-06 11:22:10,121 INFO    MainThread:12772 [wandb_init.py:init():631] backend started and connected
2024-07-06 11:22:10,126 INFO    MainThread:12772 [wandb_init.py:init():720] updated telemetry
2024-07-06 11:22:10,188 INFO    MainThread:12772 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-07-06 11:22:11,064 INFO    MainThread:12772 [wandb_run.py:_on_init():2402] communicating current version
2024-07-06 11:22:11,469 INFO    MainThread:12772 [wandb_run.py:_on_init():2411] got version response 
2024-07-06 11:22:11,469 INFO    MainThread:12772 [wandb_init.py:init():804] starting run threads in backend
2024-07-06 11:22:11,938 INFO    MainThread:12772 [wandb_run.py:_console_start():2380] atexit reg
2024-07-06 11:22:11,938 INFO    MainThread:12772 [wandb_run.py:_redirect():2235] redirect: wrap_raw
2024-07-06 11:22:11,938 INFO    MainThread:12772 [wandb_run.py:_redirect():2300] Wrapping output streams.
2024-07-06 11:22:11,938 INFO    MainThread:12772 [wandb_run.py:_redirect():2325] Redirects installed.
2024-07-06 11:22:11,941 INFO    MainThread:12772 [wandb_init.py:init():847] run started, returning control to user process
2024-07-06 11:31:12,221 WARNING MsgRouterThr:12772 [router.py:message_loop():77] message_loop has been closed
